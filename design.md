# Design Document for VS Code AI Transformers Plugin

## Introduction

The **VS Code AI Transformers Plugin** is an extension that enables AI-powered file transformations directly within Visual Studio Code. It provides a customizable interface for processing files using various AI models, automating complex workflows, and enhancing productivity. This document outlines the architecture, components, and data flow of the plugin to assist new developers in understanding the solution.

## Technology Stack

The plugin is built using the following technologies:

- **TypeScript**: The project is written in TypeScript, with the configuration set to `"module": "Node16"` and `"target": "ES2022"`. This ensures compatibility with modern JavaScript features and Node.js module resolution.

- **Mocha and Chai**: The testing framework used is Mocha, with Chai for assertions. Tests focus on high-level behavior and use mocks for VS Code modules.

## Architecture Overview

The plugin is structured into several key components:

- **Extension Activation**: Managed by `src/extension.ts`, which contains the `activate` and `deactivate` functions. These functions initialize and clean up resources when the extension is activated or deactivated in VS Code.

- **Configuration Management**: Handled by `src/config/configurationManager.ts`, which manages settings like model names, AI providers, and API keys. This component ensures that the plugin can interact with different AI models and services by storing and retrieving necessary configuration data.

- **Execution Engine**: Implemented in `src/execution/executionEngine.ts`, responsible for executing transformers based on configurations. It validates file paths, checks access permissions, and coordinates the execution of transformations.

- **Transformers Management**: Managed by `src/transformers/transformerManager.ts`, which handles the lifecycle of transformers. This includes creating, updating, deleting, and executing transformers, as well as validating their configurations.

- **Input and Output Processing**: Managed by `src/transformers/inputFileProcessor.ts` and `src/transformers/outputFileManager.ts`. These components handle the processing of input files and the management of output files generated by transformations.

## Detailed Component Descriptions

### Configuration Management

- **ConfigurationManager**: Provides static methods to get and set configuration settings, such as AI model names and API keys. It also includes methods to prompt users for API keys when needed.

### Execution Engine

- **executeTransformers**: Executes transformers based on a given configuration, validating file paths and checking access permissions. It orchestrates the entire transformation process, ensuring that input files are processed, AI models are invoked, and output files are generated correctly.

### Transformers Management

- **TransformerManager**: Manages the creation, updating, deletion, and execution of transformers. It validates transformer configurations and interacts with storage to persist transformer data. The manager ensures that transformers are executed in a controlled and efficient manner.

### Input and Output Processing

- **processInputFiles**: Handles the processing of input files for transformations. It reads and prepares files for transformation based on user-defined patterns and configurations.

- **manageOutputFiles**: Manages the output files generated after transformations. It ensures that output files are saved in the correct format and location as specified by the user.

### Language Model Factory

- **LLMBase**: An abstract class for language model clients, with subclasses like `OpenAIClient` for sending requests to AI models. These classes handle the communication with AI services, sending prompts and receiving responses.

## Data Flow

1. **Configuration**: Users configure transformers via the UI or command palette, specifying input patterns, AI prompts, and output settings. The configuration data is stored and managed by the `ConfigurationManager`.

2. **Execution**: The execution engine validates configurations and executes transformers, processing input files and generating outputs. The `TransformerManager` coordinates the execution, while the `executionEngine` handles the technical details of file processing and model interaction.

3. **Feedback**: Progress and errors are communicated to the user through feedback functions in `progressFeedback.ts`. This ensures that users are informed of the transformation status and any issues that arise.

## Key Algorithms and Logic

- **Transformer Execution**: The core logic for executing transformers is encapsulated in the `executeTransformers` function, which coordinates input processing, model interaction, and output management. It ensures that each step of the transformation process is executed in sequence and handles any errors that occur.

## Configuration and Setup

- **API Keys**: Users must configure API keys for their preferred AI providers in the VS Code settings. This allows the plugin to authenticate and interact with external AI services.

- **Transformer Setup**: Users can create transformers by specifying input patterns, prompts, and output configurations. The plugin provides a user-friendly interface for managing transformers, making it easy to customize and automate workflows.

## Testing Strategy

- **Unit Tests**: The plugin includes unit tests for key components, focusing on high-level behavior. Tests are run using Mocha and Chai, with mocks for VS Code modules. This ensures that the plugin's functionality is reliable and that changes do not introduce regressions.
